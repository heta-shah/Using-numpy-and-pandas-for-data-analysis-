{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Assignment\n",
    "* Download the \"Week_3_Assignment.ipynb\" notebook \n",
    "* Fill in the code in the cells marked with `# YOUR ANSWER HERE:` by answering the question/task defined in the cell above it starting with `GRADED:`\n",
    "* Code cells outside of `# YOUR ANSWER HERE:` will not be considered for grading. \n",
    "  * Feel free to write outside of it for debugging\n",
    "* Submit the updated notebook\n",
    "  * Make sure to save your changes before submitting it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT NECESSARY LIBRARIES AND DATA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "arr = np.arange(72).reshape(9, 8)\n",
    "data_url = 'https://raw.githubusercontent.com/plotly/datasets/master/mpg_2017.txt'\n",
    "mpg_df = pd.read_csv(data_url, sep='\\t')\n",
    "mpg_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRADED SECTION A\n",
    "\n",
    "1. Determine the shape, number of dimensions and type of elements in the numpy array arr\n",
    "2. Determine the median of all elements in arr\n",
    "3. Determine the position (not the value) of the maximum value element in arr\n",
    "4. Create an array of the same shape as arr but filled with zeros\n",
    "5. Create an array of the same shape as arr but filled with ones\n",
    "6. Create an array of the same shape as arr but where all elements are the square root values\n",
    "7. Create an array result of shape 9 by 9 resulting from multiplication of arr with transpose(arr). Hint: use np.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SECTION A ANSWER HERE (please use comments to number each of your answers)\n",
    "\n",
    "# 1. Determine the shape, number of dimensions and type of elements in the numpy array arr\n",
    "print(arr.shape)\n",
    "print(arr.ndim)\n",
    "print(arr.dtype)\n",
    "\n",
    "#2. Determine the median of all elements in arr\n",
    "print(np.median(arr))\n",
    "\n",
    "#3. Determine the position (not the value) of the maximum value element in arr\n",
    "print(arr.argmax())\n",
    "\n",
    "#4. Create an array of the same shape as arr but filled with zeros\n",
    "arr2=np.zeros((9, 8), dtype=int)\n",
    "print(arr2)\n",
    "\n",
    "#5. Create an array of the same shape as arr but filled with ones\n",
    "arr3=np.ones((9, 8), dtype=int)\n",
    "print(arr3)\n",
    "\n",
    "#6. Create an array of the same shape as arr but where all elements are the square root values\n",
    "arr4= np.sqrt(arr)\n",
    "print(arr4)\n",
    "\n",
    "#7. Create an array result of shape 9 by 9 resulting from multiplication of arr with transpose(arr). Hint: use np.dot\n",
    "arr5=np.dot(arr,np.transpose(arr))\n",
    "print(arr5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRADED SECTION B\n",
    "\n",
    "The dataframe `mpg_df` loads the dataset that contains information on various car makes and models over a number years along with information on their engine specifications, including their MPG (miles-per-gallon) rating for both `cty` (city driving) and `hwy` (highway driving)\n",
    "The dataset has already been loaded for you in the first code cell above.\n",
    " 1. Print the number of rows of the dataframe (ideally, you should format the print to put the thousands comma separator--as in `23,400` instead of `23400`\n",
    " 2. Print the names of all the columns of the dataframe\n",
    " 3. Print the 20th row of the dataframe\n",
    " 4. Which is the most fuel efficient car in the `compact` class in the whole dataset?\n",
    " 5. Which is the most fuel efficient 6 cylinder car make/model made after 2003?\n",
    " 6. Which is Subaru's least fuel efficient model in the whole dataset?\n",
    " 7. Which is the worst fuel efficient model/make in the `suv` class?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SECTION B ANSWER HERE (please use comments to number each of your answers)\n",
    "#1. Print the number of rows of the dataframe (ideally, you should format the print to put the thousands comma separator--as in `23,400` instead of `23400`\n",
    "rows = len(mpg_df.index)\n",
    "print(f\"{rows:,d}\")\n",
    "\n",
    "#2. Print the names of all the columns of the dataframe\n",
    "print(list(mpg_df.columns))\n",
    "\n",
    "#3. Print the 20th row of the dataframe\n",
    "print(mpg_df.iloc[[19]])\n",
    "\n",
    "#4. Which is the most fuel efficient car in the `compact` class in the whole dataset?\n",
    "print(' Fuel Efficiency for City in Compact class ' , mpg_df[['cty','manufacturer','model']].loc[mpg_df['class'] == 'compact'].max())\n",
    "print(' Fuel Efficiency for Highway in Compact class ' , mpg_df[['hwy','manufacturer','model']].loc[mpg_df['class'] == 'compact'].max())\n",
    "\n",
    "#5. Which is the most fuel efficient 6 cylinder car make/model made after 2003?\n",
    "print('most fuel efficient 6 cylinder car make/model made after 2003: ',mpg_df[['cty','manufacturer','model']].loc[(mpg_df['cyl'] == 6)&(mpg_df['year'] > 2003)].max())\n",
    "print('most fuel efficient 6 cylinder car make/model made after 2003: ',mpg_df[['hwy','manufacturer','model']].loc[(mpg_df['cyl'] == 6)&(mpg_df['year'] > 2003)].max())\n",
    "\n",
    "\n",
    "#6. Which is Subaru's least fuel efficient model in the whole dataset?\n",
    "print('Subaru least fuel Efficiency for City',mpg_df[['cty','model']].loc[mpg_df['manufacturer'] == 'subaru'].min())\n",
    "print('Subaru least fuel Efficiency for Highway',mpg_df[['hwy','model']].loc[mpg_df['manufacturer'] == 'subaru'].min())\n",
    "\n",
    "#7. Which is the worst fuel efficient model/make in the `suv` class?\n",
    "print(' Worst fuel Efficiency for City ' , mpg_df[['cty','manufacturer','model']].loc[mpg_df['class'] == 'suv'].min())\n",
    "print(' Worst fuel Efficiency for Highway' , mpg_df[['hwy','manufacturer','model']].loc[mpg_df['class'] == 'suv'].min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT: SECTION C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please list your top 3 (final) choices for a dataset and the datastory for each of those datasets that you would like to pursue and analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  YOUR SECTION C ANSWER HERE (please use comments to number each of your answers)\n",
    "\n",
    "#  Group members : Heta Hemang Shah,Thi Diem Tran,Shruti Avinash Pawar,Hiral Rathod\n",
    "\n",
    "#  Top 3 Datasets:### Top 3 choices for a dataset of our group are:\n",
    "\n",
    "# 1. Healthcare Stroke Dataset\n",
    "# - Link to the dataset: https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data\n",
    "# - Describe the dataset:\n",
    "#     + The dataset is about the stroke situation of patients. Each row corresponds to heart stroke based on other features such as gender, age, hypertension, heart disease, bmi, smoking status and so on.\n",
    "#     + Train dataset have 12 columns and 72,900 rows. Target variable: Stroke (0, 1)\n",
    "#     + Test dataset have 11 columns (missing Stroke classification column) and 72,900 rows\n",
    "#     + There are null values in BMI which can be replaced by mean or median. \n",
    "# - Describe the story (topic) that you intend to explore: \n",
    "#     + What factors have high contribution to the stroke?\n",
    "#     + How to determine the proportion of a person being stroke based on their information?\n",
    "# - The related questions you will be answering with the dataset\n",
    "#     + Predicting heart stroke based on other factors for test dataset. \n",
    "#     + Which models is better for stroke prediction (Logistic regression or random forest)?\n",
    "    \n",
    "\n",
    "# 2. Rain in Australia\n",
    "# - Link to the dataset: https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n",
    "# - Describe the dataset:\n",
    "#     + This dataset recored nearly 10 years of daily weather observations (October 31, 2007 to June 24, 2017) from numerous Australian weather stations\n",
    "#     + Target variable: RainTomorrow\n",
    "#     + 24 variables include temprature, rainfall, evaluation, sunshine, wind direction, wind speed, humidity, pressure and so on\n",
    "#     + To predict the weather for the next day, we should exclude the RISK_MM column because it can reveal the answer for the model\n",
    "# - Describe the story (topic) that you intend to explore:\n",
    "#     + How likely it will be rain tomorrow/other time in the future?\n",
    "# - The related questions you will be answering with the dataset\n",
    "#     + Predicting the weather by time (using time series)\n",
    "#     + Predicting whether it's raining or not tomorrow based on other weather conditions (Logistic regression)\n",
    "\n",
    "\n",
    "# 3. Women's E-Commerce Clothing Reviews\n",
    "# - Link to the dataset: https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews\n",
    "# - Describe the dataset:\n",
    "#     + The dataset is about customer review and rating for E-Commerce clothing products. Target variables for this dataset can be rating (ranging from 1 to 5) or review (text)\n",
    "#     + 23486 rows and 10 feature variables which include type of product, the text review, rating, division and department name of the product and so on.\n",
    "# - Describe the story (topic) that you intend to explore:\n",
    "#     + How other features affect the customer review?\n",
    "#     + How to define a good/bad review based on the review column itself?\n",
    "# - The related questions you will be answering with the dataset\n",
    "#     + Classifying the rating of customers based on other factors\n",
    "#     + Using text mining for the feedbacks to see the signals for good/bad review\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
